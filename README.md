# ARTIC
Attention-based transformer model for Arabic image captioning
This repository primarily focuses on deep learning tasks related to image captioning, employing cutting edge methods. The technique of creating a written description of an image through the use of computer vision and natural language processing is known as image captioning. Convolutional neural networks (CNNs) are used in the network to encode images into latent space representations. Transformers are then used to decode feature and word representations and construct language models. Testing and training are conducted using the Arabic Flickr8k dataset. 
# Data
Text: https://github.com/ObeidaElJundi/Arabic-Image-Captioning/tree/master/data/Flickr8k_text
Image: Please download Flickr8k_Dataset.zip from here: http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip
Extract Flickr8k_Dataset.zip and place Flicker8k_Dataset in Data folder
# Keywords
Arabic image captioning, Transformer, Computer vision, Natural language processing, Attention mechanism, Convolutional neural network.
# Sample of our result
![image](https://github.com/IsraaAbdullah/ARTIC/assets/47572412/fa2ac730-698d-4326-82f0-e9e70cf17544)

The generated caption by the proposed model:<start> رجل يرتدي ستره حمراء يتسلق صخره <end>

![image](https://github.com/IsraaAbdullah/ARTIC/assets/47572412/2c19d118-1fa4-4cad-af65-dcb42f54dac3)

The generated caption by the proposed model:<start> كلب ابيض واسود يلعب مع كره تنس فمه <end>

![image](https://github.com/IsraaAbdullah/ARTIC/assets/47572412/f621ab10-bec0-487f-80ad-bacf14865c5e)

The generated caption by the proposed model:<start> مجموعه من ناس يجلسون على رصيف من مبنى من طوب <end>
# Paper
to be added 
# Citation 
to be added 
